#===============================================================================
# Meta Data
#===============================================================================

metadata:
    # Language of the input documents, specified as ISO 639-3 code
    language: swe


#===============================================================================
# General Settings
#===============================================================================

import:
    # File type of the input. Must be 'xml' or 'txt'.
    source_type: xml
    # The element representing one text document. Text-level annotations will be made on this element.
    document_element: text

# Class definitions
classes:
    sentence: segment.sentence
    token: segment.token
    "token:word": <token>:misc.word


#===============================================================================
# Output Settings
#===============================================================================

# Common settings for exporters
export:
    # Chunk to scramble the XML export on
    scramble_on: <sentence>
    # Exports to create by default when running 'sparv run'
    default:
        - xml_export:pretty
    # Set to false if module name spaces should be kept in the export (e.g. 'pos' will be called 'hunpos.pos')
    remove_module_namespaces: true
    # A string representing the name space to be added to all annotations created by Sparv
    sparv_namespace: Null
    # A string representing the name space to be added to all annotations present in the source
    source_namespace: Null

#===============================================================================
# Module-specific Settings
#===============================================================================

segment:
    # Chunk to use for automatic sentence segmentation (typically <text> or nothing)
    paragraph_chunk: <text>
    # How to do automatic paragraph segmentation. Valid values: blanklines, linebreaks, whitespace, fsv_paragraph
    paragraph_segmenter: blanklines
    # Chunk to use for automatic sentence segmentation (typically <text> or <paragraph>)
    sentence_chunk: <text>
    # Chunk to use for automatic tokenisation
    token_chunk: <sentence>

saldo:
    precision: ""


#===============================================================================
# Korp and Installation
#===============================================================================
xml_export:
    # Export hosts and paths (targets for install_export and install_export_original)
    export_host: ""
    export_path: ""
    export_original_host: ""
    export_original_path: ""

korp:
    # Korp: password protected corpus
    protected: false

    # Remote host name for installation of both corpus data and database
    remote_host: ""

    # Paths on remote server (targets for install_corpus)
    remote_cwb_datadir: ""
    remote_corpus_registry: ""

    # Database name for relations, lemgram index and timespan
    mysql_dbname: ""

    # Installations to be made when running `sparv install`
    install:
        - "korp:install_corpus"
        - "korp:install_relations"
        - "korp:install_timespan"
        - "xml_export:install_original"
        - "xml_export:install_sentence_scrambled"
